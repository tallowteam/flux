---
phase: 02-performance
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - Cargo.toml
  - src/cli/args.rs
  - src/error.rs
  - src/main.rs
  - src/transfer/mod.rs
  - src/transfer/chunk.rs
  - src/transfer/parallel.rs
autonomous: true
requirements:
  - PERF-01
  - PERF-02
  - PERF-04

must_haves:
  truths:
    - "chunk_file splits a file size into N ChunkPlans with correct offsets and lengths"
    - "auto_chunk_count returns 1 for files under 10MB and scales up for larger files"
    - "read_at and write_at work correctly on Windows using seek_read/seek_write"
    - "CLI accepts --chunks, --verify, --compress, --limit, --resume flags without errors"
  artifacts:
    - path: "src/transfer/chunk.rs"
      provides: "ChunkPlan, TransferPlan, chunk_file(), auto_chunk_count()"
      contains: "pub struct ChunkPlan"
    - path: "src/transfer/parallel.rs"
      provides: "Cross-platform positional I/O: read_at, write_at, read_at_exact, write_at_all"
      contains: "pub fn read_at"
    - path: "src/cli/args.rs"
      provides: "Extended CpArgs with chunks, verify, compress, limit, resume fields"
      contains: "--chunks"
    - path: "src/error.rs"
      provides: "ChecksumMismatch, ResumeError, CompressionError variants"
      contains: "ChecksumMismatch"
  key_links:
    - from: "src/transfer/chunk.rs"
      to: "src/transfer/parallel.rs"
      via: "ChunkPlan used by positional I/O functions"
      pattern: "ChunkPlan"
    - from: "src/cli/args.rs"
      to: "src/transfer/mod.rs"
      via: "CpArgs fields consumed by execute_copy"
      pattern: "args\\.chunks|args\\.verify"
---

<objective>
Add Phase 2 dependencies and build the chunk planning infrastructure: ChunkPlan/TransferPlan types, file chunking algorithm, auto-detection heuristic, and cross-platform positional I/O primitives.

Purpose: Establish the foundational types and I/O primitives that all other Phase 2 features (parallel copy, resume, checksum, compression, throttling) depend on. Also extend the CLI to accept all Phase 2 flags.

Output: New `chunk.rs` and `parallel.rs` modules, extended CLI args, new error variants, updated Cargo.toml with blake3/zstd/rayon/serde_json/bytesize dependencies.
</objective>

<execution_context>
@C:/Users/trima/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/trima/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-performance/02-RESEARCH.md
@src/cli/args.rs
@src/error.rs
@src/transfer/mod.rs
@src/transfer/copy.rs
@Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependencies, CLI flags, and error variants</name>
  <files>
    Cargo.toml
    src/cli/args.rs
    src/error.rs
    src/main.rs
    src/transfer/mod.rs
  </files>
  <action>
1. **Cargo.toml** -- Add Phase 2 dependencies:
   ```
   blake3 = "1.8"
   zstd = "0.13"
   rayon = "1.10"
   serde_json = "1.0"
   bytesize = "1.3"
   ```
   Note: `serde` with `derive` feature already exists.

2. **src/cli/args.rs** -- Extend `CpArgs` with these fields (all optional, no behavioral change yet):
   - `--chunks N` (usize, default 0 meaning auto-detect): `#[arg(long, default_value = "0")]`
   - `--verify` (bool flag): `#[arg(long)]`
   - `--compress` (bool flag): `#[arg(long)]`
   - `--limit` (Option&lt;String&gt;): `#[arg(long)]` -- e.g., "10MB/s", "500KB/s"
   - `--resume` (bool flag): `#[arg(long)]`

3. **src/error.rs** -- Add three new variants to `FluxError`:
   - `ChecksumMismatch { path: PathBuf, expected: String, actual: String }` with message "Checksum mismatch for {path}: expected {expected}, got {actual}" and suggestion "The file may be corrupted. Try re-transferring."
   - `ResumeError(String)` with message "Resume error: {0}" and suggestion "Delete the .flux-resume.json manifest file and restart the transfer."
   - `CompressionError(String)` with message "Compression error: {0}"
   Add `From<serde_json::Error>` impl converting to `FluxError::Config(err.to_string())`.

4. **src/main.rs** -- Update the debug tracing in the `Cp` match arm to also log the new flags: `chunks`, `verify`, `compress`, `limit`, `resume`.

5. **src/transfer/mod.rs** -- Add `pub mod chunk;` and `pub mod parallel;` declarations at the top (alongside existing `pub mod copy;` and `pub mod filter;`). These modules will be empty files for now to satisfy the compiler -- create them as empty files with just a comment.

Run `cargo build` to confirm everything compiles. Run `cargo test` to confirm existing 36 tests still pass. Run `cargo run -- cp --help` to confirm the new flags appear.
  </action>
  <verify>
    `cargo build` succeeds. `cargo test` passes all existing tests. `cargo run -- cp --help` shows --chunks, --verify, --compress, --limit, --resume flags.
  </verify>
  <done>
    All Phase 2 dependencies are in Cargo.toml. CpArgs has all 5 new optional fields. FluxError has ChecksumMismatch, ResumeError, CompressionError variants. New module declarations compile. Existing 36 tests pass unchanged.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement chunk planning and positional I/O primitives</name>
  <files>
    src/transfer/chunk.rs
    src/transfer/parallel.rs
  </files>
  <action>
1. **src/transfer/chunk.rs** -- Create the chunk planning module:

   Define `ChunkPlan` struct (derive Debug, Clone, Serialize, Deserialize):
   - `index: usize`
   - `offset: u64`
   - `length: u64`
   - `completed: bool`
   - `checksum: Option<String>` (BLAKE3 hex hash of this chunk)

   Define `TransferPlan` struct (derive Debug, Serialize, Deserialize):
   - `source_path: String`
   - `dest_path: String`
   - `total_size: u64`
   - `file_checksum: Option<String>` (whole-file BLAKE3 hash)
   - `chunks: Vec<ChunkPlan>`

   Implement `chunk_file(total_size: u64, chunk_count: usize) -> Vec<ChunkPlan>`:
   - Divide total_size evenly, last chunk absorbs remainder
   - All chunks start with `completed: false`, `checksum: None`
   - Handle edge case: chunk_count=0 or total_size=0

   Implement `auto_chunk_count(file_size: u64) -> usize`:
   - < 10 MB: 1 (no chunking)
   - 10 MB - 100 MB: 2
   - 100 MB - 1 GB: 4
   - 1 GB - 10 GB: 8
   - > 10 GB: 16
   - Cap at `std::thread::available_parallelism().unwrap_or(4)`

   Add unit tests:
   - `chunk_file` with known sizes (100 bytes / 4 chunks = 25+25+25+25)
   - `chunk_file` with remainder (101 bytes / 4 chunks = 25+25+25+26)
   - `chunk_file` edge cases: size=0, count=1
   - `auto_chunk_count` returns 1 for 1MB, 2 for 50MB, 4 for 500MB, etc.

2. **src/transfer/parallel.rs** -- Create cross-platform positional I/O module:

   Implement `read_at(file: &File, offset: u64, buf: &mut [u8]) -> io::Result<usize>`:
   - `#[cfg(unix)]` uses `std::os::unix::fs::FileExt::read_at`
   - `#[cfg(windows)]` uses `std::os::windows::fs::FileExt::seek_read`

   Implement `write_at(file: &File, offset: u64, buf: &[u8]) -> io::Result<usize>`:
   - `#[cfg(unix)]` uses `std::os::unix::fs::FileExt::write_at`
   - `#[cfg(windows)]` uses `std::os::windows::fs::FileExt::seek_write`

   Implement `read_at_exact(file: &File, offset: u64, buf: &mut [u8]) -> io::Result<()>`:
   - Loop calling `read_at` until buf is filled or EOF, similar to `Read::read_exact`

   Implement `write_at_all(file: &File, offset: u64, buf: &[u8]) -> io::Result<()>`:
   - Loop calling `write_at` until all bytes written, similar to `Write::write_all`

   Add unit tests:
   - Write known bytes to a temp file, then `read_at` at various offsets and verify content
   - `write_at` at a specific offset, read back entire file and verify
   - `read_at_exact` reads correct number of bytes
   - `write_at_all` writes all bytes even if write_at returns partial
  </action>
  <verify>
    `cargo test` passes all new tests in chunk.rs and parallel.rs plus existing 36 tests. Specifically: `cargo test chunk` and `cargo test parallel` show the new tests passing.
  </verify>
  <done>
    ChunkPlan and TransferPlan types exist with serde derive. chunk_file correctly splits files into N chunks. auto_chunk_count returns correct chunk counts for various file sizes. read_at/write_at/read_at_exact/write_at_all work correctly on the current platform (Windows). All tests pass.
  </done>
</task>

</tasks>

<verification>
1. `cargo build` compiles without warnings (allow unused for new modules is OK since Plan 02/03 will use them)
2. `cargo test` passes all tests (existing 36 + new chunk/parallel tests)
3. `cargo run -- cp --help` shows all 5 new flags with descriptions
4. New modules exist: src/transfer/chunk.rs, src/transfer/parallel.rs
5. No regressions in existing single-file or directory copy functionality
</verification>

<success_criteria>
- All Phase 2 crate dependencies present in Cargo.toml and compile
- ChunkPlan/TransferPlan types are defined with serde serialization
- chunk_file and auto_chunk_count produce correct results (verified by unit tests)
- Positional I/O primitives (read_at, write_at, read_at_exact, write_at_all) work on Windows
- CLI accepts --chunks, --verify, --compress, --limit, --resume without errors
- FluxError has ChecksumMismatch, ResumeError, CompressionError variants
- All existing tests continue to pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-performance/02-01-SUMMARY.md`
</output>
